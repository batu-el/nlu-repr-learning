{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15664,"status":"ok","timestamp":1706304841764,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":0},"id":"_M_TV0S71Ur9","outputId":"2bf08492-7921-4360-f2a7-fe353884330c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/507.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/507.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Collecting transformers[torch]\n","  Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill\u003c0.3.8,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]\u003c=2023.10.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub\u003e=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Collecting responses\u003c0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n","Requirement already satisfied: torch!=1.12.0,\u003e=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.2.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.4)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.4)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.4-\u003edatasets) (4.5.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2023.11.17)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (2.1.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.3.post1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (2.1.4)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch!=1.12.0,\u003e=1.11-\u003etransformers[torch]) (1.3.0)\n","Installing collected packages: dill, responses, multiprocess, accelerate, transformers, datasets, evaluate\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 responses-0.18.0 transformers-4.37.1\n"]}],"source":["!pip install datasets evaluate transformers[torch] accelerate -U"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2282470,"status":"ok","timestamp":1706307124231,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":0},"id":"4YxonV9o1mKa","outputId":"83be0a54-510d-45a5-ea5a-7af15183441f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","drive_PATH = '../content/drive/MyDrive/Colab Notebooks/dis.experiments.4'\n","import sys\n","sys.path.append(drive_PATH)\n","# drive_PATH = ''"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4361,"status":"ok","timestamp":1706307128589,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":0},"id":"OZH1GEcx1sjd"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import tqdm\n","import math\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706307128589,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":0},"id":"wuygBoqz1uT1","outputId":"8a8b3837-89b8-4cee-cf92-dd49e6f3bd3a"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Device for GPU speedup\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","DEVICE"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28690,"status":"ok","timestamp":1706307157275,"user":{"displayName":"Batu El","userId":"11666366648103508022"},"user_tz":0},"id":"Thousf_q1xhz","outputId":"ccabba75-aa2b-4ece-fffc-6a32f8d05c36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting jsonlines\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: attrs\u003e=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.2.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-4.0.0\n"]}],"source":["### MNLI Dataset ###\n","!pip install jsonlines\n","import jsonlines # jsonl imports\n","\n","train_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_train.jsonl'\n","dev_matched_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_dev_matched.jsonl'\n","dev_mismatched_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_dev_mismatched.jsonl'\n","hans_PATH = drive_PATH + '/data/hans/heuristics_evaluation_set.jsonl'\n","\n","# Train Data\n","train_DATA = []\n","train_s1 = []\n","train_s2 = []\n","train_text = []\n","train_label = []\n","# Mathced Dev Data\n","dev_matched_DATA = []\n","dev_matched_s1 = []\n","dev_matched_s2 = []\n","dev_matched_text = []\n","dev_matched_label = []\n","# Mismatched Dev Data\n","dev_mismatched_DATA = []\n","dev_mismatched_s1 = []\n","dev_mismatched_s2 = []\n","dev_mismatched_text = []\n","dev_mismatched_label = []\n","# Hans Data\n","hans_DATA = []\n","hans_s1 = []\n","hans_s2 = []\n","hans_text = []\n","hans_label = []\n","\n","with jsonlines.open(train_PATH) as f:\n","    for line in f.iter():\n","        train_DATA.append(line)\n","        train_s1.append(line['sentence1'])\n","        train_s2.append(line['sentence2'])\n","        train_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        train_label.append(line['gold_label'])\n","with jsonlines.open(dev_matched_PATH) as f:\n","    for line in f.iter():\n","        dev_matched_DATA.append(line)\n","        dev_matched_s1.append(line['sentence1'])\n","        dev_matched_s2.append(line['sentence2'])\n","        dev_matched_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        dev_matched_label.append(line['gold_label'])\n","with jsonlines.open(dev_mismatched_PATH) as f:\n","    for line in f.iter():\n","        dev_mismatched_DATA.append(line)\n","        dev_mismatched_s1.append(line['sentence1'])\n","        dev_mismatched_s2.append(line['sentence2'])\n","        dev_mismatched_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        dev_mismatched_label.append(line['gold_label'])\n","with jsonlines.open(hans_PATH) as f:\n","    for line in f.iter():\n","        hans_DATA.append(line)\n","        hans_s1.append(line['sentence1'])\n","        hans_s2.append(line['sentence2'])\n","        hans_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        hans_label.append(line['gold_label'])\n","\n","### Cleaning Datasets\n","\n","# Train\n","train_label = np.array(train_label, dtype='\u003cU14')\n","train_s1 = np.array(train_s1)\n","train_s2 = np.array(train_s2)\n","train_label[(train_label == 'neutral') | (train_label == 'contradiction')] = 'non-entailment'\n","train_label[train_label == ['entailment']] = 1\n","train_label[train_label == ['non-entailment']] = 0\n","train_label = np.array(train_label, dtype='int')\n","\n","# Dev Matched\n","dev_matched_label = np.array(dev_matched_label, dtype='\u003cU14')\n","dev_matched_filter = dev_matched_label != '-'\n","dev_matched_s1 = np.array(dev_matched_s1)[dev_matched_filter]\n","dev_matched_s2 = np.array(dev_matched_s2)[dev_matched_filter]\n","dev_matched_label = dev_matched_label[dev_matched_filter]\n","dev_matched_label[(dev_matched_label == 'neutral') | (dev_matched_label == 'contradiction')] = 'non-entailment'\n","dev_matched_label[dev_matched_label == ['entailment']] = 1\n","dev_matched_label[dev_matched_label == ['non-entailment']] = 0\n","dev_matched_label = np.array(dev_matched_label, dtype='int')\n","\n","# Dev Mismatched\n","dev_mismatched_label = np.array(dev_mismatched_label, dtype='\u003cU14')\n","dev_mismatched_filter = dev_mismatched_label != '-'\n","dev_mismatched_s1 = np.array(dev_mismatched_s1)[dev_mismatched_filter]\n","dev_mismatched_s2 = np.array(dev_mismatched_s2)[dev_mismatched_filter]\n","dev_mismatched_label = dev_mismatched_label[dev_mismatched_filter]\n","dev_mismatched_label[(dev_mismatched_label == 'neutral') | (dev_mismatched_label == 'contradiction')] = 'non-entailment'\n","dev_mismatched_label[dev_mismatched_label == ['entailment']] = 1\n","dev_mismatched_label[dev_mismatched_label == ['non-entailment']] = 0\n","dev_mismatched_label = np.array(dev_mismatched_label, dtype='int')\n","\n","# HANS\n","hans_label = np.array(hans_label)\n","hans_s1 = np.array(hans_s1)\n","hans_s2 = np.array(hans_s2)\n","hans_label[hans_label == ['entailment']] = 1\n","hans_label[hans_label == ['non-entailment']] = 0\n","hans_label = np.array(hans_label, dtype='int')\n","\n","train_labels = np.unique(train_label)\n","dev_matched_labels = np.unique(dev_matched_label)\n","dev_mismatched_labels = np.unique(dev_mismatched_label)\n","hans_labels = np.unique(np.array(hans_label))\n","\n","value_counts = pd.concat({'train_label' : pd.DataFrame(train_label).value_counts(),\n","                        'dev_matched_label' : pd.DataFrame(dev_matched_label).value_counts(),\n","                        'dev_mismatched_label' : pd.DataFrame(dev_mismatched_label).value_counts(),\n","                        'hans_label' : pd.DataFrame(hans_label).value_counts()})\n","\n","### Balancing Act\n","def balanced_idx(label_dataset):\n","    idx1 = np.array(range(len(label_dataset)))[label_dataset == 1]\n","    idx0 = np.array(range(len(label_dataset)))[label_dataset == 0]\n","    idx0_selected_i = np.random.choice(idx0.shape[0], len(idx1), replace=False)\n","    idx0_selected = idx0[idx0_selected_i]\n","    idx = np.concatenate((idx1, idx0_selected))\n","    np.random.shuffle(idx) # random shuffle\n","    return idx\n","\n","# Balancing Train\n","train_balanced_idx = balanced_idx(train_label)\n","train_s1 = train_s1[train_balanced_idx]\n","train_s2 = train_s2[train_balanced_idx]\n","train_label = train_label[train_balanced_idx]\n","\n","# Balancing Dev Matched\n","dev_matched_balanced_idx = balanced_idx(dev_matched_label)\n","dev_matched_s1 = dev_matched_s1[dev_matched_balanced_idx]\n","dev_matched_s2 = dev_matched_s2[dev_matched_balanced_idx]\n","dev_matched_label = dev_matched_label[dev_matched_balanced_idx]\n","\n","# Balancing Dev Mismatched\n","dev_mismatched_balanced_idx = balanced_idx(dev_mismatched_label)\n","dev_mismatched_s1 = dev_mismatched_s1[dev_mismatched_balanced_idx]\n","dev_mismatched_s2 = dev_mismatched_s2[dev_mismatched_balanced_idx]\n","dev_mismatched_label = dev_mismatched_label[dev_mismatched_balanced_idx]\n","\n","# Balancing HANS (already balanced)\n","hans_balanced_idx = balanced_idx(hans_label)\n","hans_s1 = hans_s1[hans_balanced_idx]\n","hans_s2 = hans_s2[hans_balanced_idx]\n","hans_label = hans_label[hans_balanced_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":344},"id":"ena3CC4t1zQ2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7503bb85fb1450eb44368651c92790d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dcaad26ffaf42e7b35b5e755e4fa8bd","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38c39a57cddb45f48f1497424ff99eb0","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e60049d672ef4ac49c2193b245272658","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/261798 [00:00\u003c?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","100%|██████████| 261798/261798 [05:03\u003c00:00, 861.48it/s]\n","100%|██████████| 6958/6958 [00:07\u003c00:00, 871.46it/s]\n","100%|██████████| 6926/6926 [00:08\u003c00:00, 855.31it/s]\n","100%|██████████| 30000/30000 [00:25\u003c00:00, 1182.46it/s]\n"]}],"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","#####################\n","### Training Data ###\n","#####################\n","train_input_ids = []\n","train_attention_masks = []\n","train_token_type_ids = []\n","len_train = len(train_s1)\n","assert ((len(train_s1) == len_train) and (len(train_s2) == len_train))\n","for i in tqdm.tqdm(range(len_train)):\n","  encoded_dict = tokenizer.encode_plus(\n","                      train_s1[i], train_s2[i],\n","                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                      max_length = 512,           # Pad \u0026 truncate all sentences.\n","                      pad_to_max_length = True,\n","                      return_attention_mask = True,   # Construct attn. masks.\n","                      return_tensors = 'pt',     # Return pytorch tensors.\n","                  )\n","  train_input_ids.append(encoded_dict['input_ids'])\n","  train_attention_masks.append(encoded_dict['attention_mask'])\n","  train_token_type_ids.append(encoded_dict['token_type_ids'])\n","# Convert the lists into tensors\n","train_input_ids = torch.cat(train_input_ids, dim=0)\n","train_attention_masks = torch.cat(train_attention_masks, dim=0)\n","train_token_type_ids = torch.cat(train_token_type_ids, dim=0)\n","train_labels = torch.tensor(train_label)\n","\n","##########################\n","### Dev (Matched) Data ###\n","##########################\n","dev_matched_input_ids = []\n","dev_matched_attention_masks = []\n","dev_matched_token_type_ids = []\n","len_dev_matched = len(dev_matched_s1)\n","assert ((len(dev_matched_s1) == len_dev_matched) and (len(dev_matched_s2) == len_dev_matched))\n","for i in tqdm.tqdm(range(len_dev_matched)):\n","  encoded_dict = tokenizer.encode_plus(\n","                      dev_matched_s1[i], dev_matched_s2[i],\n","                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                      max_length = 512,           # Pad \u0026 truncate all sentences.\n","                      pad_to_max_length = True,\n","                      return_attention_mask = True,   # Construct attn. masks.\n","                      return_tensors = 'pt',     # Return pytorch tensors.\n","                  )\n","  dev_matched_input_ids.append(encoded_dict['input_ids'])\n","  dev_matched_attention_masks.append(encoded_dict['attention_mask'])\n","  dev_matched_token_type_ids.append(encoded_dict['token_type_ids'])\n","# Convert the lists into tensors\n","dev_matched_input_ids = torch.cat(dev_matched_input_ids, dim=0)\n","dev_matched_attention_masks = torch.cat(dev_matched_attention_masks, dim=0)\n","dev_matched_token_type_ids = torch.cat(dev_matched_token_type_ids, dim=0)\n","dev_matched_labels = torch.tensor(dev_matched_label)\n","\n","#############################\n","### Dev (Mismatched) Data ###\n","#############################\n","dev_mismatched_input_ids = []\n","dev_mismatched_attention_masks = []\n","dev_mismatched_token_type_ids = []\n","len_dev_mismatched = len(dev_mismatched_s1)\n","assert ((len(dev_mismatched_s1) == len_dev_mismatched) and (len(dev_mismatched_s2) == len_dev_mismatched))\n","for i in tqdm.tqdm(range(len_dev_mismatched)):\n","  encoded_dict = tokenizer.encode_plus(\n","                      dev_mismatched_s1[i], dev_mismatched_s2[i],\n","                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                      max_length = 512,           # Pad \u0026 truncate all sentences.\n","                      pad_to_max_length = True,\n","                      return_attention_mask = True,   # Construct attn. masks.\n","                      return_tensors = 'pt',     # Return pytorch tensors.\n","                  )\n","  dev_mismatched_input_ids.append(encoded_dict['input_ids'])\n","  dev_mismatched_attention_masks.append(encoded_dict['attention_mask'])\n","  dev_mismatched_token_type_ids.append(encoded_dict['token_type_ids'])\n","# Convert the lists into tensors\n","dev_mismatched_input_ids = torch.cat(dev_mismatched_input_ids, dim=0)\n","dev_mismatched_attention_masks = torch.cat(dev_mismatched_attention_masks, dim=0)\n","dev_mismatched_token_type_ids = torch.cat(dev_mismatched_token_type_ids, dim=0)\n","dev_mismatched_labels = torch.tensor(dev_mismatched_label)\n","\n","#################\n","### HANS Data ###\n","#################\n","hans_input_ids = []\n","hans_attention_masks = []\n","hans_token_type_ids = []\n","len_hans = len(hans_s1)\n","assert ((len(hans_s1) == len_hans) and (len(hans_s2) == len_hans))\n","for i in tqdm.tqdm(range(len_hans)):\n","  encoded_dict = tokenizer.encode_plus(\n","                      hans_s1[i], hans_s2[i],\n","                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                      max_length = 512,           # Pad \u0026 truncate all sentences.\n","                      pad_to_max_length = True,\n","                      return_attention_mask = True,   # Construct attn. masks.\n","                      return_tensors = 'pt',     # Return pytorch tensors.\n","                      )\n","  hans_input_ids.append(encoded_dict['input_ids'])\n","  hans_attention_masks.append(encoded_dict['attention_mask'])\n","  hans_token_type_ids.append(encoded_dict['token_type_ids'])\n","# Convert the lists into tensors\n","hans_input_ids = torch.cat(hans_input_ids, dim=0)\n","hans_attention_masks = torch.cat(hans_attention_masks, dim=0)\n","hans_token_type_ids = torch.cat(hans_token_type_ids, dim=0)\n","hans_labels = torch.tensor(hans_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2l5tas1E11wQ"},"outputs":[],"source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","\n","### Datasets ###\n","train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_token_type_ids, train_labels)\n","dev_matched_dataset = TensorDataset(dev_matched_input_ids, dev_matched_attention_masks, dev_matched_token_type_ids, dev_matched_labels)\n","dev_mismatched_dataset = TensorDataset(dev_mismatched_input_ids, dev_mismatched_attention_masks, dev_mismatched_token_type_ids, dev_mismatched_labels)\n","hans_dataset = TensorDataset(hans_input_ids, hans_attention_masks, hans_token_type_ids , hans_labels)\n","### Dataset Splits ###\n","# MNLI\n","num_train = int(len(train_dataset) * 0.95)\n","num_valid = len(train_dataset) - num_train #int(len(train_dataset) * 0.05)\n","split_train, split_valid = random_split( train_dataset, [num_train, num_valid] )\n","split_test_matched = dev_matched_dataset\n","split_test_mismatched = dev_mismatched_dataset\n","# HANS\n","num_train_hans = int(len(hans_dataset) * 0.80)\n","num_valid_hans = int(len(hans_dataset) * 0.10)\n","num_test_hans = len(hans_dataset) - num_train_hans - num_valid_hans #int(len(hans_dataset) * 0.10)\n","split_train_hans , split_valid_hans, split_test_hans = random_split( hans_dataset, [num_train_hans, num_valid_hans , num_test_hans] )\n","###############################\n","### Define the Data Loaders ###\n","###############################\n","BATCH_SIZE = 16\n","# MNLI\n","train_dataloader = DataLoader(split_train, batch_size=BATCH_SIZE, shuffle=True)\n","valid_dataloader = DataLoader(split_valid, batch_size=BATCH_SIZE, shuffle=True)\n","test_matched_dataloader = DataLoader(split_test_matched, batch_size=BATCH_SIZE, shuffle=True)\n","test_mismatched_dataloader = DataLoader(split_test_mismatched, batch_size=BATCH_SIZE, shuffle=True)\n","# HANS\n","hans_train_dataloader = DataLoader(split_train_hans, batch_size=BATCH_SIZE, shuffle=True)\n","hans_valid_dataloader = DataLoader(split_valid_hans, batch_size=BATCH_SIZE, shuffle=True)\n","hans_test_dataloader = DataLoader(split_test_hans, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8Qhe27Ba136P"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4179f2e2ebce48a39aa111d57b5f7114","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.1, inplace=False)\n","  (l3): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import transformers\n","########################\n","### Define the Model ###\n","########################\n","# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l2 = torch.nn.Dropout(0.1)\n","        self.l3 = torch.nn.Linear(768, 2)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n","        output_2 = self.l2(output_1)\n","        output = self.l3(output_2)\n","        # softmax_output = torch.nn.functional.softmax(output, dim=1)\n","        return output\n","model = BERTClass()\n","model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1DhOUXCL16X3"},"outputs":[],"source":["############################\n","### Define the Optimizer ###\n","############################\n","from transformers import AdamW\n","LEARNING_RATE =  2e-5\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","################################\n","### Define the Loss Function ###\n","################################\n","loss_function = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HdsXFlGS189n"},"outputs":[],"source":["##################################\n","### Define the Evaluation Loop ###\n","##################################\n","def evaluate(dataloader):\n","    model.cuda()\n","    model.eval()\n","    total_loss, total_acc, total_count, total_count_n = 0, 0, 0, 0\n","    with torch.no_grad():\n","      for step, batch in tqdm.tqdm(enumerate(dataloader)):\n","          # 0. Put ids \u0026 mask \u0026 labels to the device\n","          b_input_ids = batch[0].to(DEVICE)\n","          b_input_mask = batch[1].to(DEVICE)\n","          b_token_type_ids = batch[2].to(DEVICE)\n","          b_labels = batch[3].to(DEVICE)\n","          # 2. Forward Pass\n","          output = model(b_input_ids, b_input_mask, b_token_type_ids)\n","          logits = output\n","          predicted_class_labels = logits.argmax(dim=1)\n","          # 3. Loss\n","          valid_loss = loss_function(logits, b_labels)\n","          valid_acc = (predicted_class_labels == b_labels).sum().item()\n","          total_loss += valid_loss\n","          total_acc += valid_acc\n","          total_count += len(b_labels)\n","          total_count_n += 1\n","    Loss = total_loss / total_count_n\n","    Acc = total_acc / total_count\n","    return Loss, Acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zXSq1V9Y1_Oj"},"outputs":[{"name":"stderr","output_type":"stream","text":["101it [00:36,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   100/15545 batches | loss    0.655| accuracy    0.598\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:12,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   200/15545 batches | loss    0.552| accuracy    0.723\n"]},{"name":"stderr","output_type":"stream","text":["301it [01:47,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   300/15545 batches | loss    0.484| accuracy    0.773\n"]},{"name":"stderr","output_type":"stream","text":["401it [02:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   400/15545 batches | loss    0.455| accuracy    0.794\n"]},{"name":"stderr","output_type":"stream","text":["501it [02:58,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   500/15545 batches | loss    0.425| accuracy    0.810\n"]},{"name":"stderr","output_type":"stream","text":["601it [03:33,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   600/15545 batches | loss    0.417| accuracy    0.825\n"]},{"name":"stderr","output_type":"stream","text":["701it [04:08,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   700/15545 batches | loss    0.413| accuracy    0.824\n"]},{"name":"stderr","output_type":"stream","text":["801it [04:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   800/15545 batches | loss    0.398| accuracy    0.831\n"]},{"name":"stderr","output_type":"stream","text":["901it [05:19,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   900/15545 batches | loss    0.423| accuracy    0.814\n"]},{"name":"stderr","output_type":"stream","text":["1001it [05:54,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1000/15545 batches | loss    0.376| accuracy    0.831\n"]},{"name":"stderr","output_type":"stream","text":["1101it [06:29,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1100/15545 batches | loss    0.395| accuracy    0.828\n"]},{"name":"stderr","output_type":"stream","text":["1201it [07:05,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1200/15545 batches | loss    0.357| accuracy    0.853\n"]},{"name":"stderr","output_type":"stream","text":["1301it [07:40,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1300/15545 batches | loss    0.379| accuracy    0.827\n"]},{"name":"stderr","output_type":"stream","text":["1401it [08:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1400/15545 batches | loss    0.388| accuracy    0.824\n"]},{"name":"stderr","output_type":"stream","text":["1501it [08:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1500/15545 batches | loss    0.364| accuracy    0.838\n"]},{"name":"stderr","output_type":"stream","text":["1601it [09:26,  2.82it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1600/15545 batches | loss    0.367| accuracy    0.846\n"]},{"name":"stderr","output_type":"stream","text":["1701it [10:01,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1700/15545 batches | loss    0.359| accuracy    0.844\n"]},{"name":"stderr","output_type":"stream","text":["1801it [10:36,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1800/15545 batches | loss    0.378| accuracy    0.838\n"]},{"name":"stderr","output_type":"stream","text":["1901it [11:12,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1900/15545 batches | loss    0.366| accuracy    0.843\n"]},{"name":"stderr","output_type":"stream","text":["2001it [11:47,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2000/15545 batches | loss    0.365| accuracy    0.848\n"]},{"name":"stderr","output_type":"stream","text":["2101it [12:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2100/15545 batches | loss    0.357| accuracy    0.848\n"]},{"name":"stderr","output_type":"stream","text":["2201it [12:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2200/15545 batches | loss    0.379| accuracy    0.828\n"]},{"name":"stderr","output_type":"stream","text":["2301it [13:33,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2300/15545 batches | loss    0.357| accuracy    0.835\n"]},{"name":"stderr","output_type":"stream","text":["2401it [14:08,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2400/15545 batches | loss    0.357| accuracy    0.853\n"]},{"name":"stderr","output_type":"stream","text":["2501it [14:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2500/15545 batches | loss    0.365| accuracy    0.844\n"]},{"name":"stderr","output_type":"stream","text":["2601it [15:19,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2600/15545 batches | loss    0.341| accuracy    0.856\n"]},{"name":"stderr","output_type":"stream","text":["2701it [15:54,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2700/15545 batches | loss    0.341| accuracy    0.851\n"]},{"name":"stderr","output_type":"stream","text":["2801it [16:29,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2800/15545 batches | loss    0.318| accuracy    0.866\n"]},{"name":"stderr","output_type":"stream","text":["2901it [17:04,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  2900/15545 batches | loss    0.322| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["3001it [17:40,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3000/15545 batches | loss    0.375| accuracy    0.841\n"]},{"name":"stderr","output_type":"stream","text":["3101it [18:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3100/15545 batches | loss    0.346| accuracy    0.846\n"]},{"name":"stderr","output_type":"stream","text":["3201it [18:50,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3200/15545 batches | loss    0.350| accuracy    0.846\n"]},{"name":"stderr","output_type":"stream","text":["3301it [19:26,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3300/15545 batches | loss    0.358| accuracy    0.847\n"]},{"name":"stderr","output_type":"stream","text":["3401it [20:01,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3400/15545 batches | loss    0.329| accuracy    0.860\n"]},{"name":"stderr","output_type":"stream","text":["3501it [20:36,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3500/15545 batches | loss    0.347| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["3601it [21:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3600/15545 batches | loss    0.308| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["3701it [21:47,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3700/15545 batches | loss    0.317| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["3801it [22:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3800/15545 batches | loss    0.323| accuracy    0.869\n"]},{"name":"stderr","output_type":"stream","text":["3901it [22:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  3900/15545 batches | loss    0.318| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["4001it [23:33,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4000/15545 batches | loss    0.327| accuracy    0.850\n"]},{"name":"stderr","output_type":"stream","text":["4101it [24:08,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4100/15545 batches | loss    0.338| accuracy    0.851\n"]},{"name":"stderr","output_type":"stream","text":["4201it [24:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4200/15545 batches | loss    0.322| accuracy    0.854\n"]},{"name":"stderr","output_type":"stream","text":["4301it [25:18,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4300/15545 batches | loss    0.337| accuracy    0.853\n"]},{"name":"stderr","output_type":"stream","text":["4401it [25:54,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4400/15545 batches | loss    0.314| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["4501it [26:29,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4500/15545 batches | loss    0.328| accuracy    0.857\n"]},{"name":"stderr","output_type":"stream","text":["4601it [27:04,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4600/15545 batches | loss    0.354| accuracy    0.841\n"]},{"name":"stderr","output_type":"stream","text":["4701it [27:40,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4700/15545 batches | loss    0.338| accuracy    0.848\n"]},{"name":"stderr","output_type":"stream","text":["4801it [28:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4800/15545 batches | loss    0.312| accuracy    0.870\n"]},{"name":"stderr","output_type":"stream","text":["4901it [28:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  4900/15545 batches | loss    0.339| accuracy    0.852\n"]},{"name":"stderr","output_type":"stream","text":["5001it [29:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5000/15545 batches | loss    0.327| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["5101it [30:01,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5100/15545 batches | loss    0.321| accuracy    0.860\n"]},{"name":"stderr","output_type":"stream","text":["5201it [30:36,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5200/15545 batches | loss    0.312| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["5301it [31:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5300/15545 batches | loss    0.342| accuracy    0.844\n"]},{"name":"stderr","output_type":"stream","text":["5401it [31:47,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5400/15545 batches | loss    0.309| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["5501it [32:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5500/15545 batches | loss    0.321| accuracy    0.865\n"]},{"name":"stderr","output_type":"stream","text":["5601it [32:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5600/15545 batches | loss    0.325| accuracy    0.865\n"]},{"name":"stderr","output_type":"stream","text":["5701it [33:32,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5700/15545 batches | loss    0.334| accuracy    0.865\n"]},{"name":"stderr","output_type":"stream","text":["5801it [34:08,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5800/15545 batches | loss    0.344| accuracy    0.852\n"]},{"name":"stderr","output_type":"stream","text":["5901it [34:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  5900/15545 batches | loss    0.307| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["6001it [35:18,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6000/15545 batches | loss    0.323| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["6101it [35:54,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6100/15545 batches | loss    0.318| accuracy    0.861\n"]},{"name":"stderr","output_type":"stream","text":["6201it [36:29,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6200/15545 batches | loss    0.308| accuracy    0.879\n"]},{"name":"stderr","output_type":"stream","text":["6301it [37:04,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6300/15545 batches | loss    0.307| accuracy    0.865\n"]},{"name":"stderr","output_type":"stream","text":["6401it [37:39,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6400/15545 batches | loss    0.312| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["6501it [38:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6500/15545 batches | loss    0.328| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["6601it [38:50,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6600/15545 batches | loss    0.301| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["6701it [39:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6700/15545 batches | loss    0.311| accuracy    0.868\n"]},{"name":"stderr","output_type":"stream","text":["6801it [40:01,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6800/15545 batches | loss    0.305| accuracy    0.862\n"]},{"name":"stderr","output_type":"stream","text":["6901it [40:36,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  6900/15545 batches | loss    0.314| accuracy    0.859\n"]},{"name":"stderr","output_type":"stream","text":["7001it [41:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7000/15545 batches | loss    0.319| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["7101it [41:46,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7100/15545 batches | loss    0.330| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["7201it [42:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7200/15545 batches | loss    0.314| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["7301it [42:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7300/15545 batches | loss    0.316| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["7401it [43:32,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7400/15545 batches | loss    0.332| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["7501it [44:08,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7500/15545 batches | loss    0.313| accuracy    0.869\n"]},{"name":"stderr","output_type":"stream","text":["7601it [44:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7600/15545 batches | loss    0.331| accuracy    0.857\n"]},{"name":"stderr","output_type":"stream","text":["7701it [45:18,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7700/15545 batches | loss    0.313| accuracy    0.879\n"]},{"name":"stderr","output_type":"stream","text":["7801it [45:54,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7800/15545 batches | loss    0.297| accuracy    0.879\n"]},{"name":"stderr","output_type":"stream","text":["7901it [46:29,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  7900/15545 batches | loss    0.305| accuracy    0.875\n"]},{"name":"stderr","output_type":"stream","text":["8001it [47:04,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8000/15545 batches | loss    0.289| accuracy    0.882\n"]},{"name":"stderr","output_type":"stream","text":["8101it [47:39,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8100/15545 batches | loss    0.304| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["8201it [48:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8200/15545 batches | loss    0.326| accuracy    0.862\n"]},{"name":"stderr","output_type":"stream","text":["8301it [48:50,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8300/15545 batches | loss    0.289| accuracy    0.882\n"]},{"name":"stderr","output_type":"stream","text":["8401it [49:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8400/15545 batches | loss    0.286| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["8501it [50:01,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8500/15545 batches | loss    0.294| accuracy    0.887\n"]},{"name":"stderr","output_type":"stream","text":["8601it [50:36,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8600/15545 batches | loss    0.312| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["8701it [51:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8700/15545 batches | loss    0.336| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["8801it [51:46,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8800/15545 batches | loss    0.308| accuracy    0.867\n"]},{"name":"stderr","output_type":"stream","text":["8901it [52:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  8900/15545 batches | loss    0.300| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["9001it [52:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9000/15545 batches | loss    0.305| accuracy    0.882\n"]},{"name":"stderr","output_type":"stream","text":["9101it [53:32,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9100/15545 batches | loss    0.328| accuracy    0.861\n"]},{"name":"stderr","output_type":"stream","text":["9201it [54:08,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9200/15545 batches | loss    0.312| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["9301it [54:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9300/15545 batches | loss    0.296| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["9401it [55:18,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9400/15545 batches | loss    0.318| accuracy    0.861\n"]},{"name":"stderr","output_type":"stream","text":["9501it [55:53,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9500/15545 batches | loss    0.314| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["9601it [56:29,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9600/15545 batches | loss    0.295| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["9701it [57:04,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9700/15545 batches | loss    0.289| accuracy    0.887\n"]},{"name":"stderr","output_type":"stream","text":["9801it [57:39,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9800/15545 batches | loss    0.296| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["9901it [58:15,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  9900/15545 batches | loss    0.292| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["10001it [58:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10000/15545 batches | loss    0.288| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["10101it [59:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10100/15545 batches | loss    0.327| accuracy    0.863\n"]},{"name":"stderr","output_type":"stream","text":["10201it [1:00:00,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10200/15545 batches | loss    0.310| accuracy    0.866\n"]},{"name":"stderr","output_type":"stream","text":["10301it [1:00:36,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10300/15545 batches | loss    0.292| accuracy    0.870\n"]},{"name":"stderr","output_type":"stream","text":["10401it [1:01:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10400/15545 batches | loss    0.300| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["10501it [1:01:46,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10500/15545 batches | loss    0.286| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["10601it [1:02:22,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10600/15545 batches | loss    0.316| accuracy    0.869\n"]},{"name":"stderr","output_type":"stream","text":["10701it [1:02:57,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10700/15545 batches | loss    0.301| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["10801it [1:03:32,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10800/15545 batches | loss    0.296| accuracy    0.883\n"]},{"name":"stderr","output_type":"stream","text":["10901it [1:04:07,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 10900/15545 batches | loss    0.300| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["11001it [1:04:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11000/15545 batches | loss    0.323| accuracy    0.870\n"]},{"name":"stderr","output_type":"stream","text":["11101it [1:05:18,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11100/15545 batches | loss    0.283| accuracy    0.879\n"]},{"name":"stderr","output_type":"stream","text":["11201it [1:05:53,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11200/15545 batches | loss    0.320| accuracy    0.872\n"]},{"name":"stderr","output_type":"stream","text":["11301it [1:06:29,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11300/15545 batches | loss    0.312| accuracy    0.871\n"]},{"name":"stderr","output_type":"stream","text":["11401it [1:07:04,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11400/15545 batches | loss    0.313| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["11501it [1:07:39,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11500/15545 batches | loss    0.296| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["11601it [1:08:14,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11600/15545 batches | loss    0.292| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["11701it [1:08:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11700/15545 batches | loss    0.293| accuracy    0.880\n"]},{"name":"stderr","output_type":"stream","text":["11801it [1:09:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11800/15545 batches | loss    0.295| accuracy    0.877\n"]},{"name":"stderr","output_type":"stream","text":["11901it [1:10:00,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 11900/15545 batches | loss    0.277| accuracy    0.883\n"]},{"name":"stderr","output_type":"stream","text":["12001it [1:10:36,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12000/15545 batches | loss    0.301| accuracy    0.880\n"]},{"name":"stderr","output_type":"stream","text":["12101it [1:11:11,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12100/15545 batches | loss    0.334| accuracy    0.859\n"]},{"name":"stderr","output_type":"stream","text":["12201it [1:11:46,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12200/15545 batches | loss    0.295| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["12301it [1:12:21,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12300/15545 batches | loss    0.310| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["12401it [1:12:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12400/15545 batches | loss    0.315| accuracy    0.865\n"]},{"name":"stderr","output_type":"stream","text":["12501it [1:13:32,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12500/15545 batches | loss    0.286| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["12601it [1:14:07,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12600/15545 batches | loss    0.301| accuracy    0.882\n"]},{"name":"stderr","output_type":"stream","text":["12701it [1:14:43,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12700/15545 batches | loss    0.281| accuracy    0.889\n"]},{"name":"stderr","output_type":"stream","text":["12801it [1:15:18,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12800/15545 batches | loss    0.300| accuracy    0.877\n"]},{"name":"stderr","output_type":"stream","text":["12901it [1:15:53,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 12900/15545 batches | loss    0.316| accuracy    0.864\n"]},{"name":"stderr","output_type":"stream","text":["13001it [1:16:28,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13000/15545 batches | loss    0.300| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["13101it [1:17:04,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13100/15545 batches | loss    0.263| accuracy    0.887\n"]},{"name":"stderr","output_type":"stream","text":["13201it [1:17:39,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13200/15545 batches | loss    0.288| accuracy    0.886\n"]},{"name":"stderr","output_type":"stream","text":["13301it [1:18:14,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13300/15545 batches | loss    0.316| accuracy    0.873\n"]},{"name":"stderr","output_type":"stream","text":["13401it [1:18:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13400/15545 batches | loss    0.302| accuracy    0.870\n"]},{"name":"stderr","output_type":"stream","text":["13501it [1:19:25,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13500/15545 batches | loss    0.295| accuracy    0.877\n"]},{"name":"stderr","output_type":"stream","text":["13601it [1:20:00,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13600/15545 batches | loss    0.284| accuracy    0.888\n"]},{"name":"stderr","output_type":"stream","text":["13701it [1:20:35,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13700/15545 batches | loss    0.307| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["13801it [1:21:11,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13800/15545 batches | loss    0.267| accuracy    0.904\n"]},{"name":"stderr","output_type":"stream","text":["13901it [1:21:46,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 13900/15545 batches | loss    0.300| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["14001it [1:22:21,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14000/15545 batches | loss    0.269| accuracy    0.896\n"]},{"name":"stderr","output_type":"stream","text":["14101it [1:22:57,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14100/15545 batches | loss    0.303| accuracy    0.880\n"]},{"name":"stderr","output_type":"stream","text":["14201it [1:23:32,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14200/15545 batches | loss    0.309| accuracy    0.868\n"]},{"name":"stderr","output_type":"stream","text":["14301it [1:24:07,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14300/15545 batches | loss    0.316| accuracy    0.862\n"]},{"name":"stderr","output_type":"stream","text":["14401it [1:24:43,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14400/15545 batches | loss    0.312| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["14501it [1:25:18,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14500/15545 batches | loss    0.303| accuracy    0.870\n"]},{"name":"stderr","output_type":"stream","text":["14601it [1:25:53,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14600/15545 batches | loss    0.278| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["14701it [1:26:28,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14700/15545 batches | loss    0.294| accuracy    0.876\n"]},{"name":"stderr","output_type":"stream","text":["14801it [1:27:04,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14800/15545 batches | loss    0.283| accuracy    0.888\n"]},{"name":"stderr","output_type":"stream","text":["14901it [1:27:39,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 14900/15545 batches | loss    0.259| accuracy    0.897\n"]},{"name":"stderr","output_type":"stream","text":["15001it [1:28:14,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15000/15545 batches | loss    0.305| accuracy    0.874\n"]},{"name":"stderr","output_type":"stream","text":["15101it [1:28:50,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15100/15545 batches | loss    0.290| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["15201it [1:29:25,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15200/15545 batches | loss    0.300| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["15301it [1:30:00,  2.83it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15300/15545 batches | loss    0.284| accuracy    0.881\n"]},{"name":"stderr","output_type":"stream","text":["15401it [1:30:35,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15400/15545 batches | loss    0.288| accuracy    0.884\n"]},{"name":"stderr","output_type":"stream","text":["15501it [1:31:11,  2.84it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 | 15500/15545 batches | loss    0.294| accuracy    0.880\n"]},{"name":"stderr","output_type":"stream","text":["15545it [1:31:26,  2.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------\n","| end of epoch   1 | time: 5486.47s |\n","-----------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["819it [01:33,  8.74it/s]\n","435it [00:49,  8.73it/s]\n","433it [00:49,  8.72it/s]\n","188it [00:21,  8.76it/s]\n","188it [00:21,  8.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["| Validation Loss    0.289 | Validation Accuracy    0.879\n","| Test Matched Loss    0.290 | Test Matched Accuracy    0.877\n","| Test Mismatched Loss    0.278 | Test Mismatched Accuracy    0.883\n","| HANS Validation Loss    1.868 | HANS Validation Accuracy    0.506\n","| HANS Test Loss    1.929 | HANS Test Accuracy    0.491\n","-----------------------------------------------------------\n"]}],"source":["# TRAINING \u0026 VALIDATION\n","import time\n","EPOCHS = 1\n","\n","model_paths = []\n","# MNLI Losses\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","test_matched_losses, test_matched_accs = [], []\n","test_mismatched_losses, test_mismatched_accs = [], []\n","# HANS Losses\n","hans_train_losses , hans_train_accs  = [], []\n","hans_valid_losses, hans_valid_accs  = [], []\n","hans_test_losses, hans_test_accs = [], []\n","# Model ID\n","model_id = '-'.join(time.ctime(time.time()).replace(':', ' ').split(' ')[2:5])\n","\n","# DATALOADERS\n","# MNLI\n","train_dataloader = DataLoader(split_train, batch_size=BATCH_SIZE, shuffle=True)\n","valid_dataloader = DataLoader(split_valid, batch_size=BATCH_SIZE, shuffle=True)\n","test_matched_dataloader = DataLoader(split_test_matched, batch_size=BATCH_SIZE, shuffle=True)\n","test_mismatched_dataloader = DataLoader(split_test_mismatched, batch_size=BATCH_SIZE, shuffle=True)\n","# HANS\n","hans_train_dataloader = DataLoader(split_train_hans, batch_size=BATCH_SIZE, shuffle=True)\n","hans_valid_dataloader = DataLoader(split_valid_hans, batch_size=BATCH_SIZE, shuffle=True)\n","hans_test_dataloader = DataLoader(split_test_hans, batch_size=BATCH_SIZE, shuffle=True)\n","\n","### EPOCHS ###\n","for epoch in range(1, EPOCHS + 1):\n","    ################\n","    ### TRAINING ###\n","    ################\n","    epoch_start_time = time.time()\n","    ############################################################################\n","    model.cuda()\n","    model.train()\n","    total_loss, total_acc, total_count = 0, 0, 0\n","    log_interval = 100\n","    dataloader = train_dataloader # CHANGE TO TRAIN DATALOADER\n","    for step, batch in tqdm.tqdm(enumerate(dataloader)):\n","        # 0. Put ids \u0026 mask \u0026 labels to the device\n","        b_input_ids = batch[0].to(DEVICE)\n","        b_input_mask = batch[1].to(DEVICE)\n","        b_token_type_ids = batch[2].to(DEVICE)\n","        b_labels = batch[3].to(DEVICE)\n","        # 1. Clear Gradient\n","        optimizer.zero_grad()\n","        # 2. Forward Pass\n","        output = model(b_input_ids, b_input_mask, b_token_type_ids)\n","        logits = output                        # predicted probabilities\n","        predicted_class_labels = logits.argmax(dim=1) # predicted classes\n","        # 3. Loss\n","        train_loss = loss_function(logits, b_labels)\n","        # 4. Backward Pass\n","        train_loss.backward()\n","        # 5. Optimizer Step\n","        optimizer.step()\n","        # 6. Progress Display\n","        train_acc = (predicted_class_labels == b_labels).sum().item() / len(b_labels)\n","        total_loss += train_loss.item()\n","        total_acc += train_acc\n","        total_count += 1\n","        if step % log_interval == 0 and step \u003e 0:\n","            loss = total_loss / total_count\n","            acc = total_acc / total_count\n","            train_losses.append(loss)\n","            train_accs.append(acc)\n","            print(\"| epoch {: d} | {:5d}/{:5d} batches \"\n","                  \"| loss {:8.3f}| accuracy {:8.3f}\".format(epoch, step, len(dataloader),loss , acc))\n","            total_loss, total_acc, total_count = 0, 0, 0\n","    ############################################################################\n","    epoch_end_time = time.time()\n","    training_time = epoch_end_time - epoch_start_time\n","    print(\"-\" * 59)\n","    print(\"| end of epoch {:3d} | time: {:5.2f}s |\".format( epoch, training_time))\n","    print(\"-\" * 59)\n","    ##################\n","    ### VALIDATION ###\n","    ##################\n","    # Training\n","    loss_train = train_losses[-1]\n","    acc_train = train_accs[-1]\n","    # Validation\n","    loss_val, acc_val = evaluate(valid_dataloader)\n","    val_losses.append(loss_val)\n","    val_accs.append(acc_val)\n","    # Test Matched\n","    loss_test_matched, acc_test_matched = evaluate(test_matched_dataloader)\n","    test_matched_losses.append(loss_test_matched)\n","    test_matched_accs.append(acc_test_matched)\n","    # Test Mismatched\n","    loss_test_mismatched, acc_test_mismatched = evaluate(test_mismatched_dataloader)\n","    test_mismatched_losses.append(loss_test_mismatched)\n","    test_mismatched_accs.append(acc_test_mismatched)\n","    # Hans Validation\n","    loss_hans_valid, acc_hans_valid = evaluate(hans_valid_dataloader)\n","    hans_valid_losses.append(loss_hans_valid)\n","    hans_valid_accs.append(acc_hans_valid)\n","    # Hans Test\n","    loss_hans_test , acc_hans_test = evaluate(hans_test_dataloader)\n","    hans_test_losses.append(loss_hans_test)\n","    hans_test_accs.append(acc_hans_test)\n","    # Register model path\n","    model_paths.append(f'id-{model_id}-epoch-{epoch}-acc_train-{acc_train:.2f}-acc_val-{acc_val:.2f}.pt')\n","    # Save model to path\n","    torch.save(model.state_dict(), drive_PATH+'/model_states/'+model_paths[-1])\n","    # Display Results\n","    print(\"| Validation Loss {:8.3f} | Validation Accuracy {:8.3f}\".format( loss_val, acc_val))\n","    print(\"| Test Matched Loss {:8.3f} | Test Matched Accuracy {:8.3f}\".format( loss_test_matched, acc_test_matched))\n","    print(\"| Test Mismatched Loss {:8.3f} | Test Mismatched Accuracy {:8.3f}\".format( loss_test_mismatched, acc_test_mismatched))\n","    print(\"| HANS Validation Loss {:8.3f} | HANS Validation Accuracy {:8.3f}\".format( loss_hans_valid, acc_hans_valid))\n","    print(\"| HANS Test Loss {:8.3f} | HANS Test Accuracy {:8.3f}\".format( loss_hans_test, acc_hans_test))\n","    print(\"-\" * 59)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"K_rSu5DX2Bkq"},"outputs":[{"data":{"text/plain":["[tensor(0.2891, device='cuda:0')]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Load the model with best validation accuracy\n","best_model_index = np.argmin([l.cpu() for l in val_losses])\n","model_state = model_paths[best_model_index]\n","model.load_state_dict(torch.load(drive_PATH+'/model_states/'+model_state))\n","val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZZs3bHijui8S"},"outputs":[],"source":["# Freeze parameters in the first convolutional layer\n","for name, param in model.named_parameters():\n","    if name.startswith('l1'):\n","        param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"irm_UxJ-v_jm"},"outputs":[{"name":"stderr","output_type":"stream","text":["102it [00:12,  8.26it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   100/ 1500 batches | loss    0.981| accuracy    0.487\n"]},{"name":"stderr","output_type":"stream","text":["202it [00:24,  8.29it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   200/ 1500 batches | loss    0.690| accuracy    0.555\n"]},{"name":"stderr","output_type":"stream","text":["302it [00:36,  8.25it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   300/ 1500 batches | loss    0.687| accuracy    0.549\n"]},{"name":"stderr","output_type":"stream","text":["402it [00:48,  8.26it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   400/ 1500 batches | loss    0.689| accuracy    0.561\n"]},{"name":"stderr","output_type":"stream","text":["502it [01:00,  8.28it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   500/ 1500 batches | loss    0.689| accuracy    0.553\n"]},{"name":"stderr","output_type":"stream","text":["602it [01:12,  8.31it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   600/ 1500 batches | loss    0.688| accuracy    0.545\n"]},{"name":"stderr","output_type":"stream","text":["702it [01:24,  8.32it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   700/ 1500 batches | loss    0.684| accuracy    0.549\n"]},{"name":"stderr","output_type":"stream","text":["802it [01:36,  8.29it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   800/ 1500 batches | loss    0.685| accuracy    0.549\n"]},{"name":"stderr","output_type":"stream","text":["902it [01:48,  8.31it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |   900/ 1500 batches | loss    0.679| accuracy    0.574\n"]},{"name":"stderr","output_type":"stream","text":["1002it [02:00,  8.26it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1000/ 1500 batches | loss    0.689| accuracy    0.547\n"]},{"name":"stderr","output_type":"stream","text":["1102it [02:12,  8.32it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1100/ 1500 batches | loss    0.681| accuracy    0.569\n"]},{"name":"stderr","output_type":"stream","text":["1202it [02:24,  8.31it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1200/ 1500 batches | loss    0.680| accuracy    0.574\n"]},{"name":"stderr","output_type":"stream","text":["1302it [02:36,  8.27it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1300/ 1500 batches | loss    0.687| accuracy    0.537\n"]},{"name":"stderr","output_type":"stream","text":["1402it [02:49,  8.31it/s]"]},{"name":"stdout","output_type":"stream","text":["| epoch  1 |  1400/ 1500 batches | loss    0.688| accuracy    0.542\n"]},{"name":"stderr","output_type":"stream","text":["1500it [03:00,  8.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------\n","| end of epoch   1 | time: 180.84s |\n","-----------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["819it [01:33,  8.74it/s]\n","435it [00:49,  8.73it/s]\n","433it [00:49,  8.72it/s]\n","188it [00:21,  8.73it/s]\n","188it [00:21,  8.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["| Validation Loss    0.560 | Validation Accuracy    0.704\n","| Test Matched Loss    0.578 | Test Matched Accuracy    0.686\n","| Test Mismatched Loss    0.578 | Test Mismatched Accuracy    0.684\n","| HANS Validation Loss    0.680 | HANS Validation Accuracy    0.558\n","| HANS Test Loss    0.683 | HANS Test Accuracy    0.544\n","-----------------------------------------------------------\n"]}],"source":["### EPOCHS ###\n","for epoch in range(1, EPOCHS + 1):\n","    ################\n","    ### TRAINING ###\n","    ################\n","    epoch_start_time = time.time()\n","    ############################################################################\n","    model.cuda()\n","    model.train()\n","    total_loss, total_acc, total_count = 0, 0, 0\n","    log_interval = 100\n","    dataloader = hans_train_dataloader # CHANGE TO TRAIN DATALOADER\n","    for step, batch in tqdm.tqdm(enumerate(dataloader)):\n","        # 0. Put ids \u0026 mask \u0026 labels to the device\n","        b_input_ids = batch[0].to(DEVICE)\n","        b_input_mask = batch[1].to(DEVICE)\n","        b_token_type_ids = batch[2].to(DEVICE)\n","        b_labels = batch[3].to(DEVICE)\n","        # 1. Clear Gradient\n","        optimizer.zero_grad()\n","        # 2. Forward Pass\n","        output = model(b_input_ids, b_input_mask, b_token_type_ids)\n","        logits = output                        # predicted probabilities\n","        predicted_class_labels = logits.argmax(dim=1) # predicted classes\n","        # 3. Loss\n","        train_loss = loss_function(logits, b_labels)\n","        # 4. Backward Pass\n","        train_loss.backward()\n","        # 5. Optimizer Step\n","        optimizer.step()\n","        # 6. Progress Display\n","        train_acc = (predicted_class_labels == b_labels).sum().item() / len(b_labels)\n","        total_loss += train_loss.item()\n","        total_acc += train_acc\n","        total_count += 1\n","        if step % log_interval == 0 and step \u003e 0:\n","            loss = total_loss / total_count\n","            acc = total_acc / total_count\n","            train_losses.append(loss)\n","            train_accs.append(acc)\n","            print(\"| epoch {: d} | {:5d}/{:5d} batches \"\n","                  \"| loss {:8.3f}| accuracy {:8.3f}\".format(epoch, step, len(dataloader),loss , acc))\n","            total_loss, total_acc, total_count = 0, 0, 0\n","    ############################################################################\n","    epoch_end_time = time.time()\n","    training_time = epoch_end_time - epoch_start_time\n","    print(\"-\" * 59)\n","    print(\"| end of epoch {:3d} | time: {:5.2f}s |\".format( epoch, training_time))\n","    print(\"-\" * 59)\n","    ##################\n","    ### VALIDATION ###\n","    ##################\n","    # Training\n","    loss_train = train_losses[-1]\n","    acc_train = train_accs[-1]\n","    # Validation\n","    loss_val, acc_val = evaluate(valid_dataloader)\n","    val_losses.append(loss_val)\n","    val_accs.append(acc_val)\n","    # Test Matched\n","    loss_test_matched, acc_test_matched = evaluate(test_matched_dataloader)\n","    test_matched_losses.append(loss_test_matched)\n","    test_matched_accs.append(acc_test_matched)\n","    # Test Mismatched\n","    loss_test_mismatched, acc_test_mismatched = evaluate(test_mismatched_dataloader)\n","    test_mismatched_losses.append(loss_test_mismatched)\n","    test_mismatched_accs.append(acc_test_mismatched)\n","    # Hans Validation\n","    loss_hans_valid, acc_hans_valid = evaluate(hans_valid_dataloader)\n","    hans_valid_losses.append(loss_hans_valid)\n","    hans_valid_accs.append(acc_hans_valid)\n","    # Hans Test\n","    loss_hans_test , acc_hans_test = evaluate(hans_test_dataloader)\n","    hans_test_losses.append(loss_hans_test)\n","    hans_test_accs.append(acc_hans_test)\n","    # Register model path\n","    model_paths.append(f'id-{model_id}-epoch-{epoch}-acc_train-{acc_train:.2f}-acc_val-{acc_val:.2f}.pt')\n","    # Save model to path\n","    torch.save(model.state_dict(), drive_PATH+'/model_states/'+model_paths[-1])\n","    # Display Results\n","    print(\"| Validation Loss {:8.3f} | Validation Accuracy {:8.3f}\".format( loss_val, acc_val))\n","    print(\"| Test Matched Loss {:8.3f} | Test Matched Accuracy {:8.3f}\".format( loss_test_matched, acc_test_matched))\n","    print(\"| Test Mismatched Loss {:8.3f} | Test Mismatched Accuracy {:8.3f}\".format( loss_test_mismatched, acc_test_mismatched))\n","    print(\"| HANS Validation Loss {:8.3f} | HANS Validation Accuracy {:8.3f}\".format( loss_hans_valid, acc_hans_valid))\n","    print(\"| HANS Test Loss {:8.3f} | HANS Test Accuracy {:8.3f}\".format( loss_hans_test, acc_hans_test))\n","    print(\"-\" * 59)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iawOjtrNxFn_"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOy7WpoeTty1LQu3xQqVwcp","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"061c792b85d14c69bc6a2e9a714b8aba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12966bee5b5f4385b294bee938163311","placeholder":"​","style":"IPY_MODEL_33e8a301483e4ffa90276c3ee582cde3","value":"vocab.txt: 100%"}},"0c5c1d6cf47d406b9b537d86d41d406f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cddd08e89004f85ac9227a8e567c366":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10bf49dc1b2d4d0fad582c1b9569a328":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_285b896fedc2446e9493b94915e540ac","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_235564943daa43189eb1e8ddcf5005db","value":466062}},"12966bee5b5f4385b294bee938163311":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e6491bf25194aa6b32d5565d168aadf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"235564943daa43189eb1e8ddcf5005db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"285b896fedc2446e9493b94915e540ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d3e0c25c3ce498a8127bc12997313aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33e8a301483e4ffa90276c3ee582cde3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34a41e98717e40e5b026c4c43f1f529f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db94c068f0fa40829d7892a5440c72e3","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b22685fbdc884d228f3e6735c1cc2da0","value":570}},"36a60694fa0a4be9b33330ea2f4b397c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c39a57cddb45f48f1497424ff99eb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf421aac8db9467bafab7f1896e45d4b","IPY_MODEL_10bf49dc1b2d4d0fad582c1b9569a328","IPY_MODEL_c7ac815a2e554ad990da1461bddff893"],"layout":"IPY_MODEL_519910ec8b28414292687ec24db54f8f"}},"46b726e3ad194879be08fb628ff56706":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"519910ec8b28414292687ec24db54f8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56aae504fd0449038853f462791da6d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b726e3ad194879be08fb628ff56706","placeholder":"​","style":"IPY_MODEL_6a2068db6f3540b68cf9505e10a996ae","value":"tokenizer_config.json: 100%"}},"5c917638601e4250854c79db59087447":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6366b69b5cab412e808ad9dee99afa10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"658d0f68496f4846b9532a734c9bc64f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69003d7b1d434314a1046e3ee59910ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a2068db6f3540b68cf9505e10a996ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dcaad26ffaf42e7b35b5e755e4fa8bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_061c792b85d14c69bc6a2e9a714b8aba","IPY_MODEL_7bb62d61b0b8449a9d14e5dc55fb9656","IPY_MODEL_e02f7fec083d43968a5467e3b1deafef"],"layout":"IPY_MODEL_e97d8bbc9e7b4a8590915fdccc061bdb"}},"7b06fb2697cc4622b473d94785499978":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bb62d61b0b8449a9d14e5dc55fb9656":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8422d67762624b24b9aa006dbdeedbb9","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cabf5f4e84db4fc8a4f90a8c175995b4","value":231508}},"802b409e6a3148328685d2920609f31d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8422d67762624b24b9aa006dbdeedbb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d58fe2410034f14a6ece4079664cc53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8cb2d2e36b24b8c880be9d4eacf407d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c5c1d6cf47d406b9b537d86d41d406f","placeholder":"​","style":"IPY_MODEL_1e6491bf25194aa6b32d5565d168aadf","value":" 28.0/28.0 [00:00\u0026lt;00:00, 2.28kB/s]"}},"b22685fbdc884d228f3e6735c1cc2da0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf421aac8db9467bafab7f1896e45d4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc51832948f848b39bbbfaecca9b7aa4","placeholder":"​","style":"IPY_MODEL_5c917638601e4250854c79db59087447","value":"tokenizer.json: 100%"}},"c7ac815a2e554ad990da1461bddff893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6366b69b5cab412e808ad9dee99afa10","placeholder":"​","style":"IPY_MODEL_658d0f68496f4846b9532a734c9bc64f","value":" 466k/466k [00:00\u0026lt;00:00, 957kB/s]"}},"cabf5f4e84db4fc8a4f90a8c175995b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc51832948f848b39bbbfaecca9b7aa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d647dfbe2a6d47afb4f684c3fb9cd4b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7503bb85fb1450eb44368651c92790d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56aae504fd0449038853f462791da6d4","IPY_MODEL_df710813de974b9caa9f92747553ddfc","IPY_MODEL_a8cb2d2e36b24b8c880be9d4eacf407d"],"layout":"IPY_MODEL_36a60694fa0a4be9b33330ea2f4b397c"}},"db94c068f0fa40829d7892a5440c72e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df710813de974b9caa9f92747553ddfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff3c03715f3b429f971d7a8804c4d9ca","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d647dfbe2a6d47afb4f684c3fb9cd4b0","value":28}},"e02f7fec083d43968a5467e3b1deafef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69003d7b1d434314a1046e3ee59910ed","placeholder":"​","style":"IPY_MODEL_2d3e0c25c3ce498a8127bc12997313aa","value":" 232k/232k [00:00\u0026lt;00:00, 13.7MB/s]"}},"e60049d672ef4ac49c2193b245272658":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f323f56695784549818a423085388a7b","IPY_MODEL_34a41e98717e40e5b026c4c43f1f529f","IPY_MODEL_f5a0b0f7c0af4b6a86b5819b1d30f6bb"],"layout":"IPY_MODEL_f92ea72f40a1488cb40df09658b9974a"}},"e97d8bbc9e7b4a8590915fdccc061bdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f323f56695784549818a423085388a7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d58fe2410034f14a6ece4079664cc53","placeholder":"​","style":"IPY_MODEL_0cddd08e89004f85ac9227a8e567c366","value":"config.json: 100%"}},"f5a0b0f7c0af4b6a86b5819b1d30f6bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_802b409e6a3148328685d2920609f31d","placeholder":"​","style":"IPY_MODEL_7b06fb2697cc4622b473d94785499978","value":" 570/570 [00:00\u0026lt;00:00, 53.9kB/s]"}},"f92ea72f40a1488cb40df09658b9974a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff3c03715f3b429f971d7a8804c4d9ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}