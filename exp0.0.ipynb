{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4a0Lll6wsX7Q","executionInfo":{"status":"ok","timestamp":1706104033425,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["### Baseline ###"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Iis2hOBqsX7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104035513,"user_tz":0,"elapsed":2092,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"cd3d97e1-fd48-4df4-c1da-1013f8fd6b18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","drive_PATH = '../content/drive/MyDrive/Colab Notebooks/dis.experiments.4'\n","import sys\n","sys.path.append(drive_PATH)\n","# drive_PATH = ''"]},{"cell_type":"code","source":["sys.path"],"metadata":{"id":"w2o6rEUTsw-s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104035513,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"0e72a5ef-497f-46ab-d158-0c123598b6e7"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content',\n"," '/env/python',\n"," '/usr/lib/python310.zip',\n"," '/usr/lib/python3.10',\n"," '/usr/lib/python3.10/lib-dynload',\n"," '',\n"," '/usr/local/lib/python3.10/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.10/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '../content/drive/MyDrive/Colab Notebooks/dis.experiments.4']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"AAxwwUB-sX7T","executionInfo":{"status":"ok","timestamp":1706104037659,"user_tz":0,"elapsed":2149,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","import utils.NLIdataset as nli_ds\n","import utils.transforms as tr\n","\n","import tqdm\n","import math\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"iaXYxAh4sX7T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104037659,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"e8c7b327-8604-4139-d720-d0a5a2413c18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":5}],"source":["# Device for GPU speedup\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","DEVICE"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AX50sjwNsX7T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104050066,"user_tz":0,"elapsed":12410,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"70c475f7-0f37-4464-8381-2c3bf983dce8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.2.0)\n"]}],"source":["### MNLI Dataset ###\n","!pip install jsonlines\n","import jsonlines # jsonl imports\n","\n","train_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_train.jsonl'\n","dev_matched_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_dev_matched.jsonl'\n","dev_mismatched_PATH = drive_PATH + '/data/multinli_1.0/multinli_1.0_dev_mismatched.jsonl'\n","hans_PATH = drive_PATH + '/data/hans/heuristics_evaluation_set.jsonl'\n","\n","# Train Data\n","train_DATA = []\n","train_s1 = []\n","train_s2 = []\n","train_text = []\n","train_label = []\n","# Mathced Dev Data\n","dev_matched_DATA = []\n","dev_matched_s1 = []\n","dev_matched_s2 = []\n","dev_matched_text = []\n","dev_matched_label = []\n","# Mismatched Dev Data\n","dev_mismatched_DATA = []\n","dev_mismatched_s1 = []\n","dev_mismatched_s2 = []\n","dev_mismatched_text = []\n","dev_mismatched_label = []\n","# Hans Data\n","hans_DATA = []\n","hans_s1 = []\n","hans_s2 = []\n","hans_text = []\n","hans_label = []\n","\n","with jsonlines.open(train_PATH) as f:\n","    for line in f.iter():\n","        train_DATA.append(line)\n","        train_s1.append(line['sentence1'])\n","        train_s2.append(line['sentence2'])\n","        train_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        train_label.append(line['gold_label'])\n","with jsonlines.open(dev_matched_PATH) as f:\n","    for line in f.iter():\n","        dev_matched_DATA.append(line)\n","        dev_matched_s1.append(line['sentence1'])\n","        dev_matched_s2.append(line['sentence2'])\n","        dev_matched_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        dev_matched_label.append(line['gold_label'])\n","with jsonlines.open(dev_mismatched_PATH) as f:\n","    for line in f.iter():\n","        dev_mismatched_DATA.append(line)\n","        dev_mismatched_s1.append(line['sentence1'])\n","        dev_mismatched_s2.append(line['sentence2'])\n","        dev_mismatched_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        dev_mismatched_label.append(line['gold_label'])\n","with jsonlines.open(hans_PATH) as f:\n","    for line in f.iter():\n","        hans_DATA.append(line)\n","        hans_s1.append(line['sentence1'])\n","        hans_s2.append(line['sentence2'])\n","        hans_text.append( line['sentence1'] + ' ' + line['sentence2'] )\n","        hans_label.append(line['gold_label'])\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TPmDK5j1sX7U","executionInfo":{"status":"ok","timestamp":1706104052827,"user_tz":0,"elapsed":1239,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["### Cleaning Datasets\n","\n","# Train\n","train_label = np.array(train_label, dtype='<U14')\n","train_s1 = np.array(train_s1)\n","train_s2 = np.array(train_s2)\n","train_label[(train_label == 'neutral') | (train_label == 'contradiction')] = 'non-entailment'\n","train_label[train_label == ['entailment']] = 1\n","train_label[train_label == ['non-entailment']] = 0\n","train_label = np.array(train_label, dtype='int')\n","\n","# Dev Matched\n","dev_matched_label = np.array(dev_matched_label, dtype='<U14')\n","dev_matched_filter = dev_matched_label != '-'\n","dev_matched_s1 = np.array(dev_matched_s1)[dev_matched_filter]\n","dev_matched_s2 = np.array(dev_matched_s2)[dev_matched_filter]\n","dev_matched_label = dev_matched_label[dev_matched_filter]\n","dev_matched_label[(dev_matched_label == 'neutral') | (dev_matched_label == 'contradiction')] = 'non-entailment'\n","dev_matched_label[dev_matched_label == ['entailment']] = 1\n","dev_matched_label[dev_matched_label == ['non-entailment']] = 0\n","dev_matched_label = np.array(dev_matched_label, dtype='int')\n","\n","# Dev Mismatched\n","dev_mismatched_label = np.array(dev_mismatched_label, dtype='<U14')\n","dev_mismatched_filter = dev_mismatched_label != '-'\n","dev_mismatched_s1 = np.array(dev_mismatched_s1)[dev_mismatched_filter]\n","dev_mismatched_s2 = np.array(dev_mismatched_s2)[dev_mismatched_filter]\n","dev_mismatched_label = dev_mismatched_label[dev_mismatched_filter]\n","dev_mismatched_label[(dev_mismatched_label == 'neutral') | (dev_mismatched_label == 'contradiction')] = 'non-entailment'\n","dev_mismatched_label[dev_mismatched_label == ['entailment']] = 1\n","dev_mismatched_label[dev_mismatched_label == ['non-entailment']] = 0\n","dev_mismatched_label = np.array(dev_mismatched_label, dtype='int')\n","\n","# HANS\n","hans_label = np.array(hans_label)\n","hans_s1 = np.array(hans_s1)\n","hans_s2 = np.array(hans_s2)\n","hans_label[hans_label == ['entailment']] = 1\n","hans_label[hans_label == ['non-entailment']] = 0\n","hans_label = np.array(hans_label, dtype='int')\n","\n","train_labels = np.unique(train_label)\n","dev_matched_labels = np.unique(dev_matched_label)\n","dev_mismatched_labels = np.unique(dev_mismatched_label)\n","hans_labels = np.unique(np.array(hans_label))\n","\n","value_counts = pd.concat({'train_label' : pd.DataFrame(train_label).value_counts(),\n","                        'dev_matched_label' : pd.DataFrame(dev_matched_label).value_counts(),\n","                        'dev_mismatched_label' : pd.DataFrame(dev_mismatched_label).value_counts(),\n","                        'hans_label' : pd.DataFrame(hans_label).value_counts()})"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Aec-6tCBsX7U","executionInfo":{"status":"ok","timestamp":1706104054131,"user_tz":0,"elapsed":1306,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["### Balancing Act\n","def balanced_idx(label_dataset):\n","    idx1 = np.array(range(len(label_dataset)))[label_dataset == 1]\n","    idx0 = np.array(range(len(label_dataset)))[label_dataset == 0]\n","    idx0_selected_i = np.random.choice(idx0.shape[0], len(idx1), replace=False)\n","    idx0_selected = idx0[idx0_selected_i]\n","    idx = np.concatenate((idx1, idx0_selected))\n","    np.random.shuffle(idx) # random shuffle\n","    return idx\n","\n","# Balancing Train\n","train_balanced_idx = balanced_idx(train_label)\n","train_s1 = train_s1[train_balanced_idx]\n","train_s2 = train_s2[train_balanced_idx]\n","train_label = train_label[train_balanced_idx]\n","\n","# Balancing Dev Matched\n","dev_matched_balanced_idx = balanced_idx(dev_matched_label)\n","dev_matched_s1 = dev_matched_s1[dev_matched_balanced_idx]\n","dev_matched_s2 = dev_matched_s2[dev_matched_balanced_idx]\n","dev_matched_label = dev_matched_label[dev_matched_balanced_idx]\n","\n","# Balancing Dev Mismatched\n","dev_mismatched_balanced_idx = balanced_idx(dev_mismatched_label)\n","dev_mismatched_s1 = dev_mismatched_s1[dev_mismatched_balanced_idx]\n","dev_mismatched_s2 = dev_mismatched_s2[dev_mismatched_balanced_idx]\n","dev_mismatched_label = dev_mismatched_label[dev_mismatched_balanced_idx]\n","\n","# Balancing HANS (already balanced)\n","hans_balanced_idx = balanced_idx(hans_label)\n","hans_s1 = hans_s1[hans_balanced_idx]\n","hans_s2 = hans_s2[hans_balanced_idx]\n","hans_label = hans_label[hans_balanced_idx]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"okuViO0DsX7V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104062164,"user_tz":0,"elapsed":8036,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"a2aaff01-d13e-42b2-8539-88d7da852f26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["82054"]},"metadata":{},"execution_count":9}],"source":["### Preprocessing ###\n","vocab_train_iter = nli_ds.NLIdataset_merge(train_text , np.array(train_label, dtype='str'))\n","token_transform = tr.construct_token_transform()\n","vocab_transform = tr.construct_vocab_transform(vocab_train_iter)\n","tensor_transform = tr.construct_tensor_transform()\n","text_transform = tr.construct_text_transform(token_transform , vocab_transform, tensor_transform)\n","VOCAB_SIZE = len(vocab_transform)\n","VOCAB_SIZE"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"WG0dourdsX7V","executionInfo":{"status":"ok","timestamp":1706104171908,"user_tz":0,"elapsed":415,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["from model.embedding import TokenEmbedding, PositionalEncoding\n","from model.classifier import NonLinearClassifier\n","from model.encoder import Transformer_Encoder\n","\n","\n","### Natural Language Inference Model\n","class NLInference(nn.Module):\n","    def __init__(self):\n","        super(NLInference, self).__init__()\n","        # Configuration and Initialization\n","        self.dmodel = 256                       # All\n","        self.num_enc_layers = 2                 # Encoder\n","        self.nhead = 4                          # Encoder: For Transformer\n","        self.dclassifier = 2*self.dmodel        # Classifier: Calculate the input dimension for the classifier\n","        self.fc_dim = 512                       # Classifier: Dimension of the fully connected layers\n","        self.n_classes = 2                      # Classifier: Number of classes for classification\n","\n","        # Encoders\n","        self.encoder = Transformer_Encoder( self.dmodel , self.nhead, self.num_enc_layers, VOCAB_SIZE )\n","        # Classifiers\n","        self.classifier = NonLinearClassifier(self.dclassifier, self.fc_dim, self.n_classes)\n","\n","    def forward(self, s1, s2):\n","        # padding masks\n","        # s1_padding_mask = (s1 == tr.PAD_IDX).transpose(0, 1)\n","        # s2_padding_mask = (s2 == tr.PAD_IDX).transpose(0, 1)\n","        # add masks s1_padding_mask, s2_padding_mask\n","        # s1_emb = self.positional_encoding(self.tok_emb(s1))\n","        # s2_emb = self.positional_encoding(self.tok_emb(s2))\n","        # pass embeddings through encoder\n","        s1_encoded = self.encoder(s1)\n","        s2_encoded = self.encoder(s2)\n","        # take the average to calculate sentence representation\n","        # s1_encoded = torch.sum(s1_encoded,0) / s1_encoded.size()[0]\n","        # s2_encoded = torch.sum(s2_encoded,0) / s2_encoded.size()[0]\n","        # combine the two sentences by concatenating\n","        combined_context = torch.cat((s1_encoded, s2_encoded), 1)\n","        # Pass the combined features through the classifier to get the output\n","        output = self.classifier(combined_context)\n","        return output"]},{"cell_type":"code","source":[],"metadata":{"id":"O7xV-ewfra5v","executionInfo":{"status":"ok","timestamp":1706104062164,"user_tz":0,"elapsed":21,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"V1yWjkJJsX7V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706104062165,"user_tz":0,"elapsed":22,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"f67a80b8-d323-49ef-b4b3-c62a4604ebd5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["model = NLInference()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"SMTj18tVsX7V","executionInfo":{"status":"ok","timestamp":1706104062165,"user_tz":0,"elapsed":19,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["### TRAINING LOOP\n","import time\n","def train(dataloader):\n","    # print('HERE')\n","    model.cuda()\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 100\n","    start_time = time.time()\n","\n","    for idx, (s1, s2, label) in enumerate(dataloader):\n","        s1 = s1.to(DEVICE)\n","        s2 = s2.to(DEVICE)\n","        label = label.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        predicted_label = model(s1, s2)\n","\n","        loss = criterion(predicted_label, label)\n","        loss.backward()\n","\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) # investigate\n","\n","        optimizer.step()\n","\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","\n","        train_acc = total_acc / total_count\n","\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print(\n","                \"| epoch {: d} | {:5d}/{:5d} batches \"\n","                \"| accuracy {:8.3f}\".format(epoch, idx, len(dataloader), train_acc)\n","            )\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","        train_losses.append(train_acc)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kVehdRE5sX7V","executionInfo":{"status":"ok","timestamp":1706104062165,"user_tz":0,"elapsed":19,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["### EVALUATION LOOP\n","def evaluate(dataloader):\n","    model.cuda()\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (s1, s2, label) in enumerate(dataloader):\n","            s1 = s1.to(DEVICE)\n","            s2 = s2.to(DEVICE)\n","            label = label.to(DEVICE)\n","            predicted_label = model(s1, s2)\n","            loss = criterion(predicted_label, label)\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc / total_count"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BdN8BhiwsX7V","executionInfo":{"status":"ok","timestamp":1706104065632,"user_tz":0,"elapsed":3485,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","from torch.utils.data import DataLoader\n","\n","# Hyperparameters\n","EPOCHS = 4  # epoch\n","LEARNING_RATE = 0.0001  # learning rate\n","BATCH_SIZE = 16  # batch size for training\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","\n","train_iter = nli_ds.NLIdataset(train_s1 , train_s2, train_label)\n","dev_matched_iter = nli_ds.NLIdataset(dev_matched_s1, dev_matched_s2 , dev_matched_label)\n","dev_mismatched_iter = nli_ds.NLIdataset(dev_mismatched_s1, dev_mismatched_s2 , dev_mismatched_label)\n","hans_iter = nli_ds.NLIdataset(hans_s1, hans_s2 , hans_label)\n","\n","train_dataset = to_map_style_dataset(train_iter)\n","dev_matched_dataset = to_map_style_dataset(dev_matched_iter)\n","dev_mismatched_dataset = to_map_style_dataset(dev_mismatched_iter)\n","hans_dataset = to_map_style_dataset(hans_iter)\n","\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = random_split( train_dataset, [num_train, len(train_dataset) - num_train] )\n","num_train_hans = int(len(hans_dataset) * 0.75)\n","split_train_hans_ , split_test_hans_ = random_split( hans_dataset, [num_train_hans, len(hans_dataset) - num_train_hans] )\n","\n","def collate_fn( batch):\n","    label_pipeline = lambda x: int(x) #{'contradiction': 0, 'entailment': 1, 'neutral': 2, '-': -1}[x]\n","    # lists to hold processed source and target\n","    s1_batch, s2_batch, tgt_batch, padding_offsets = [], [], [],  []\n","    for s1_sample, s2_sample, tgt_sample in batch:\n","        # convert to tensor\n","        s1_sample = text_transform(s1_sample)\n","        s2_sample = text_transform(s2_sample)\n","        s1_batch.append(s1_sample)\n","        s2_batch.append(s2_sample)\n","        tgt_batch.append(label_pipeline(tgt_sample))\n","        padding_offsets.append(len(s1_sample))\n","        padding_offsets.append(len(s2_sample))\n","    # Convert the label_list to a tensor with integer type.\n","    tgt_batch = torch.tensor(tgt_batch, dtype=torch.int64)\n","    # to make the padded sequences for s1 and s2 equal length\n","    padding_offset = max(padding_offsets)\n","    s1_batch[0] = nn.ConstantPad1d((0,padding_offset - len(s1_batch[0]) ), tr.PAD_IDX)(s1_batch[0])\n","    s2_batch[0] = nn.ConstantPad1d((0,padding_offset - len(s2_batch[0]) ), tr.PAD_IDX)(s2_batch[0])\n","    # pad the sequences to ensure they have the same length\n","    s1_batch = torch.nn.utils.rnn.pad_sequence(s1_batch, padding_value=tr.PAD_IDX)\n","    s2_batch = torch.nn.utils.rnn.pad_sequence(s2_batch, padding_value=tr.PAD_IDX)\n","    return s1_batch.to(DEVICE), s2_batch.to(DEVICE), tgt_batch.to(DEVICE)\n","\n","train_dataloader = DataLoader( split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )\n","valid_dataloader = DataLoader( split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )\n","dev_matched_dataloader = DataLoader( dev_matched_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )\n","dev_mismatched_dataloader = DataLoader( dev_mismatched_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )\n","\n","train_hans_dataloader = DataLoader( split_train_hans_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )\n","test_hans_dataloader = DataLoader( split_test_hans_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn )"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qABDhCB-sX7W","colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"status":"error","timestamp":1706104067430,"user_tz":0,"elapsed":1817,"user":{"displayName":"Batu El","userId":"11666366648103508022"}},"outputId":"ec99ee6c-99e7-4814-d010-66f35d84407c"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (16x256 and 512x512)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-1bb1806addea>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mepoch_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_end_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-103282449ba8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-d072c0afb620>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s1, s2)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcombined_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Pass the combined features through the classifier to get the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/../content/drive/MyDrive/Colab Notebooks/dis.experiments.4/model/classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, combined_context)\u001b[0m\n\u001b[1;32m     22\u001b[0m             )\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x256 and 512x512)"]}],"source":["### INITIALIZATION\n","# for p in model.parameters():\n","#     if p.dim() > 1:\n","#         torch.nn.init.xavier_uniform_(p)\n","\n","### ACCOUNTING\n","model_paths = []\n","val_losses = []\n","train_losses = []\n","import time\n","model_id = '-'.join(time.ctime(time.time()).replace(':', ' ').split(' ')[2:5])\n","\n","### TRAINING\n","for epoch in range(1, EPOCHS + 1):\n","\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    epoch_end_time = time.time()\n","    elapsed_time = epoch_end_time - epoch_start_time\n","\n","    accu_train = train_losses[-1]\n","    accu_val = evaluate(valid_dataloader)\n","    val_losses.append(accu_val)\n","\n","    accu_dev_matched = evaluate(dev_matched_dataloader)\n","    accu_dev_mismatched = evaluate(dev_mismatched_dataloader)\n","    accu_hans = evaluate(test_hans_dataloader)\n","\n","    # register model path\n","    model_paths.append(f'id-{model_id}-epoch-{epoch}-accu_train-{accu_train:.3f}-accu_val-{accu_val:.3f}-accu_dev_matched-{accu_dev_matched:.3f}-accu_dev_mismatched-{accu_dev_mismatched:.3f}-accu_hans-{accu_hans:.3f}.pt')\n","    # save model to path\n","    torch.save(model.state_dict(), drive_PATH+'/model_states/'+model_paths[-1])\n","\n","\n","    print(\"-\" * 59)\n","    print(\"| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} |\".format( epoch, elapsed_time, accu_val))\n","    print(\"| dev matched accuracy {:8.3f} | dev mismatched accuracy {:8.3f} | hans accuracy {:8.3f} |\".format( accu_dev_matched, accu_dev_mismatched, accu_hans))\n","    print(\"-\" * 59)\n","\n","\n"]},{"cell_type":"code","source":["# Load the model with best validation accuracy\n","best_model_index = np.argmin(val_losses)\n","model_state = model_paths[best_model_index]\n","model.load_state_dict(torch.load(drive_PATH+'/model_states/'+model_state))"],"metadata":{"id":"FsvRhFBNMccc","executionInfo":{"status":"aborted","timestamp":1706104067431,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_losses"],"metadata":{"id":"4y6jrA2gSNNW","executionInfo":{"status":"aborted","timestamp":1706104067432,"user_tz":0,"elapsed":6,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYuGBT6jsX7W","executionInfo":{"status":"aborted","timestamp":1706104067432,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["import collections\n","from functools import partial\n","\n","NUM_BATCHES = 100\n","s1_dataset, s2_dataset, labels_dataset = [] , [], []\n","for idx, (s1, s2, label) in enumerate(valid_dataloader):\n","\tif idx == NUM_BATCHES:\n","\t\tbreak\n","\ts1_dataset.append(s1)\n","\ts2_dataset.append(s2)\n","\tlabels_dataset.append(label)\n","\n","# a dictionary that keeps saving the activations as they come\n","activations = collections.defaultdict(list)\n","def save_activation(name, mod, inp, out):\n","\tactivations[name].append(out.cpu())\n","\n","# Registering hooks for all the TransformerEncoder layers\n","# Note: Hooks are called EVERY TIME the module performs a forward pass. For modules that are\n","# called repeatedly at different stages of the forward pass (like TransformerEncoder in NLI called for s1 and s2 separately)\n","# this will save different activations.\n","# Editing the forward pass code to save activations is the way to go for these cases.\n","# Or we can filter out the odd and even indices from the activations to get the ones for s1 and s2\n","for name, m in model.named_modules():\n","\tif name == 'encoder':\n","\t\t# partial to assign the layer name to each hook\n","\t\tm.register_forward_hook(partial(save_activation, name))\n","\tif name == 'classifier.classifier.1':\n","\t\tm.register_forward_hook(partial(save_activation, name))\n","\tif name == 'classifier.classifier.4':\n","\t\tm.register_forward_hook(partial(save_activation, name))\n","\tif name == 'classifier.classifier.7':\n","\t\tm.register_forward_hook(partial(save_activation, name))\n","\n","# forward pass through the full dataset\n","for batch_i in range(NUM_BATCHES):\n","\tout = model(s1_dataset[batch_i], s2_dataset[batch_i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UjrM50XsX7W","executionInfo":{"status":"aborted","timestamp":1706104067432,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["keys = list(activations.keys())\n","activations_dict = {}\n","activations_df_dict = {}\n","for key in keys:\n","    activations_dict[key] = np.array(torch.cat([a.detach() for a in activations[key]])).transpose(1,0)\n","    activations_df_dict[key] = pd.DataFrame(activations_dict[key])\n","    print(activations_dict[key].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jxeDPCDsX7W","executionInfo":{"status":"aborted","timestamp":1706104067432,"user_tz":0,"elapsed":5,"user":{"displayName":"Batu El","userId":"11666366648103508022"}}},"outputs":[],"source":["activations_df = pd.concat(activations_df_dict, axis=0)\n","out_csv_PATH = drive_PATH + \"/res/activations/Baseline/test.csv\"\n","activations_df.to_csv(out_csv_PATH)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}